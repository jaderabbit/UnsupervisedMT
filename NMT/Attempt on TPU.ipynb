{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attempt on TPU.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ikNFFGD2a1Ky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "e93ae33d-0748-4231-bd15-e6756cb6e1fe"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oYhy9Vx3MQCS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "dffd6358-b1c6-4cb5-dbb7-0508789fca46"
      },
      "cell_type": "code",
      "source": [
        "# Install pytorch using wheel\n",
        "\n",
        "!pip3 install torch torchvision"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 26kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x58eec000 @  0x7fc1590712a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 20.8MB/s \n",
            "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-0.4.1 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D9o5IdtMed3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "51e29c22-1054-47f0-bbfd-3b4030173056"
      },
      "cell_type": "code",
      "source": [
        "# Install the github repo\n",
        "!git clone https://github.com/jaderabbit/UnsupervisedMT.git\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'UnsupervisedMT'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 95 (delta 13), reused 19 (delta 8), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (95/95), done.\n",
            "/bin/bash: ./get_my_data.sh: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HOad2OKLewzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5505
        },
        "outputId": "c481ef83-5819-4bb2-8429-f2d81789b130"
      },
      "cell_type": "code",
      "source": [
        "# cd into github repo\n",
        "# Run preparation\n",
        "!cd UnsupervisedMT/NMT; ./get_my_data.sh zu https://github.com/LauraMartinus/ukuxhumana/raw/master/leipzig/web_2013_100K_mono.zu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===== Input parameters\n",
            " source: en\n",
            " target: zu\n",
            " target monolingual url: https://github.com/LauraMartinus/ukuxhumana/raw/master/leipzig/web_2013_100K_mono.zu\n",
            " \n",
            "Cloning Moses from GitHub repository...\n",
            "Cloning into 'mosesdecoder'...\n",
            "remote: Enumerating objects: 147198, done.\u001b[K\n",
            "remote: Total 147198 (delta 0), reused 0 (delta 0), pack-reused 147198\u001b[K\n",
            "Receiving objects: 100% (147198/147198), 129.67 MiB | 20.61 MiB/s, done.\n",
            "Resolving deltas: 100% (113765/113765), done.\n",
            "Moses found in: /content/UnsupervisedMT/NMT/tools/mosesdecoder\n",
            "Cloning fastBPE from GitHub repository...\n",
            "Cloning into 'fastBPE'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Total 24 (delta 0), reused 0 (delta 0), pack-reused 24\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n",
            "fastBPE found in: /content/UnsupervisedMT/NMT/tools/fastBPE\n",
            "Compiling fastBPE...\n",
            "fastBPE compiled in: /content/UnsupervisedMT/NMT/tools/fastBPE/fast\n",
            "Cloning fastText from GitHub repository...\n",
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 2729 (delta 42), reused 52 (delta 23), pack-reused 2638\u001b[K\n",
            "Receiving objects: 100% (2729/2729), 7.72 MiB | 20.17 MiB/s, done.\n",
            "Resolving deltas: 100% (1687/1687), done.\n",
            "fastText found in: /content/UnsupervisedMT/NMT/tools/fastText\n",
            "Compiling fastText...\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/args.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/dictionary.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/productquantizer.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/matrix.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/qmatrix.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/vector.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/model.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/utils.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/meter.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/fasttext.cc\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::printLabelStats(std::istream&, int32_t, fasttext::real) const\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:445:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid fasttext::FastText::writePerLabelMetrics(std::ostream&, fasttext::Meter&) const\u001b[m\u001b[K’ is deprecated: This function is deprecated and will be removed along with `printLabelStats`. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   writePerLabelMetrics(std::cout, meter\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ksrc/fasttext.cc:10:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.h:126:8:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   void \u001b[01;36m\u001b[KwritePerLabelMetrics\u001b[m\u001b[K(std::ostream&, Meter&) const;\n",
            "        \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops args.o dictionary.o productquantizer.o matrix.o qmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n",
            "\u001b[01m\u001b[Ksrc/main.cc:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid test(const std::vector<std::__cxx11::basic_string<char> >&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/main.cc:159:51:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid fasttext::FastText::writePerLabelMetrics(std::ostream&, fasttext::Meter&) const\u001b[m\u001b[K’ is deprecated: This function is deprecated and will be removed along with `printLabelStats`. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     fasttext.writePerLabelMetrics(std::cout, meter\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ksrc/main.cc:15:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.h:126:8:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   void \u001b[01;36m\u001b[KwritePerLabelMetrics\u001b[m\u001b[K(std::ostream&, Meter&) const;\n",
            "        \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "fastText compiled in: /content/UnsupervisedMT/NMT/tools/fastText/fasttext\n",
            "Downloading English files...\n",
            "--2018-11-21 18:29:13--  http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2007.en.shuffled.gz\n",
            "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
            "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206963851 (197M) [application/x-gzip]\n",
            "Saving to: ‘news.2007.en.shuffled.gz’\n",
            "\n",
            "news.2007.en.shuffl 100%[===================>] 197.38M  1.55MB/s    in 2m 20s  \n",
            "\n",
            "2018-11-21 18:31:33 (1.41 MB/s) - ‘news.2007.en.shuffled.gz’ saved [206963851/206963851]\n",
            "\n",
            "Downloading zu files...\n",
            "--2018-11-21 18:31:33--  https://github.com/LauraMartinus/ukuxhumana/raw/master/leipzig/web_2013_100K_mono.zu\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/leipzig/web_2013_100K_mono.zu [following]\n",
            "--2018-11-21 18:31:33--  https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/leipzig/web_2013_100K_mono.zu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11324613 (11M) [text/plain]\n",
            "Saving to: ‘mono.zu’\n",
            "\n",
            "mono.zu             100%[===================>]  10.80M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-11-21 18:31:33 (77.9 MB/s) - ‘mono.zu’ saved [11324613/11324613]\n",
            "\n",
            "Decompressing news.2007.en.shuffled.gz...\n",
            "ERROR: Number of lines doesn't match! Be sure you have 100000 sentences in your EN monolingual data.\n",
            "Truncating file...\n",
            "Tokenize monolingual data...\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 48\n",
            "Tokenizer Version 1.1\n",
            "Language: zu\n",
            "Number of threads: 48\n",
            "WARNING: No known abbreviations for language 'zu', attempting fall-back to English version...\n",
            "EN monolingual data tokenized in: /content/UnsupervisedMT/NMT/data/mono/mono.en.tok\n",
            "zu monolingual data tokenized in: /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok\n",
            "Learning BPE codes...\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.en.tok ...\n",
            "Read 2363848 words (100949 unique) from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok ...\n",
            "Read 1557623 words (349064 unique) from text file.\n",
            "tcmalloc: large alloc 12000002048 bytes == 0x56023b990000 @  0x7ff898163887 0x56023089f6fd 0x5602308947ef 0x7ff89759eb97 0x560230894a1a\n",
            "BPE learned in /content/UnsupervisedMT/NMT/data/mono/bpe_codes\n",
            "Applying BPE codes...\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.en.tok ...\n",
            "Read 2363848 words (100949 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/mono/mono.en.tok ...\n",
            "Modified 2363848 words from text file.\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok ...\n",
            "Read 1557623 words (254822 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok ...\n",
            "Modified 1557623 words from text file.\n",
            "BPE codes applied to EN in: /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000\n",
            "BPE codes applied to zu in: /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000\n",
            "Extracting vocabulary...\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000 ...\n",
            "Read 2592092 words (30336 unique) from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000 ...\n",
            "Read 2057480 words (42782 unique) from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000 ...\n",
            "Read 2592092 words (30336 unique) from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000 ...\n",
            "Read 2057480 words (59437 unique) from text file.\n",
            "EN vocab in: /content/UnsupervisedMT/NMT/data/mono/vocab.en.60000\n",
            "zu vocab in: /content/UnsupervisedMT/NMT/data/mono/vocab.zu.60000\n",
            "Full vocab in: /content/UnsupervisedMT/NMT/data/mono/vocab.en-zu.60000\n",
            "Binarizing data...\n",
            "INFO - 11/21/18 18:32:45 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000.pth ...\n",
            "INFO - 11/21/18 18:32:48 - 0:00:03 - 2592092 words (59451 unique) in 100000 sentences.\n",
            "INFO - 11/21/18 18:32:48 - 0:00:03 - 0 unknown word.\n",
            "INFO - 11/21/18 18:32:49 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000.pth ...\n",
            "INFO - 11/21/18 18:32:52 - 0:00:03 - 2057480 words (59451 unique) in 100000 sentences.\n",
            "INFO - 11/21/18 18:32:52 - 0:00:03 - 0 unknown word.\n",
            "EN binarized data in: /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000.pth\n",
            "zu binarized data in: /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000.pth\n",
            "Downloading parallel data...\n",
            "--2018-11-21 18:32:52--  https://github.com/LauraMartinus/ukuxhumana/raw/master/clean/en_zu/enzu_parallel.dev.en\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.dev.en [following]\n",
            "--2018-11-21 18:32:52--  https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.dev.en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 586751 (573K) [text/plain]\n",
            "Saving to: ‘enzu_parallel.dev.en’\n",
            "\n",
            "enzu_parallel.dev.e 100%[===================>] 573.00K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2018-11-21 18:32:52 (5.94 MB/s) - ‘enzu_parallel.dev.en’ saved [586751/586751]\n",
            "\n",
            "--2018-11-21 18:32:52--  https://github.com/LauraMartinus/ukuxhumana/raw/master/clean/en_zu/enzu_parallel.dev.zu\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.dev.zu [following]\n",
            "--2018-11-21 18:32:52--  https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.dev.zu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 623825 (609K) [text/plain]\n",
            "Saving to: ‘enzu_parallel.dev.zu’\n",
            "\n",
            "enzu_parallel.dev.z 100%[===================>] 609.20K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2018-11-21 18:32:52 (9.63 MB/s) - ‘enzu_parallel.dev.zu’ saved [623825/623825]\n",
            "\n",
            "--2018-11-21 18:32:52--  https://github.com/LauraMartinus/ukuxhumana/raw/master/clean/en_zu/enzu_parallel.test.en\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.test.en [following]\n",
            "--2018-11-21 18:32:53--  https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.test.en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 377479 (369K) [text/plain]\n",
            "Saving to: ‘enzu_parallel.test.en’\n",
            "\n",
            "enzu_parallel.test. 100%[===================>] 368.63K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2018-11-21 18:32:53 (7.21 MB/s) - ‘enzu_parallel.test.en’ saved [377479/377479]\n",
            "\n",
            "--2018-11-21 18:32:53--  https://github.com/LauraMartinus/ukuxhumana/raw/master/clean/en_zu/enzu_parallel.test.zu\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.test.zu [following]\n",
            "--2018-11-21 18:32:53--  https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.test.zu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 403406 (394K) [text/plain]\n",
            "Saving to: ‘enzu_parallel.test.zu’\n",
            "\n",
            "enzu_parallel.test. 100%[===================>] 393.95K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2018-11-21 18:32:53 (7.66 MB/s) - ‘enzu_parallel.test.zu’ saved [403406/403406]\n",
            "\n",
            "Extracting parallel data...\n",
            "Tokenizing valid and test data...\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 48\n",
            "Tokenizer Version 1.1\n",
            "Language: zu\n",
            "Number of threads: 48\n",
            "WARNING: No known abbreviations for language 'zu', attempting fall-back to English version...\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 48\n",
            "Tokenizer Version 1.1\n",
            "Language: zu\n",
            "Number of threads: 48\n",
            "WARNING: No known abbreviations for language 'zu', attempting fall-back to English version...\n",
            "Applying BPE to valid and test files...\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/vocab.en.60000 ...\n",
            "Read 2592092 words (30336 unique) from vocabulary file.\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.en ...\n",
            "Read 104371 words (8205 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.en ...\n",
            "Modified 104371 words from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/vocab.zu.60000 ...\n",
            "Read 2057480 words (42782 unique) from vocabulary file.\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.zu ...\n",
            "Read 73915 words (20623 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.zu ...\n",
            "Modified 73915 words from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/vocab.en.60000 ...\n",
            "Read 2592092 words (30336 unique) from vocabulary file.\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.en ...\n",
            "Read 65604 words (6694 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.en ...\n",
            "Modified 65604 words from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/vocab.zu.60000 ...\n",
            "Read 2057480 words (42782 unique) from vocabulary file.\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.zu ...\n",
            "Read 48512 words (14309 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.zu ...\n",
            "Modified 48512 words from text file.\n",
            "Binarizing data...\n",
            "INFO - 11/21/18 18:32:57 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.en.60000.pth ...\n",
            "INFO - 11/21/18 18:32:57 - 0:00:00 - 113806 words (59451 unique) in 5019 sentences.\n",
            "INFO - 11/21/18 18:32:57 - 0:00:00 - 0 unknown word.\n",
            "INFO - 11/21/18 18:32:58 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.zu.60000.pth ...\n",
            "INFO - 11/21/18 18:32:58 - 0:00:00 - 113824 words (59451 unique) in 5019 sentences.\n",
            "INFO - 11/21/18 18:32:58 - 0:00:00 - 0 unknown word.\n",
            "INFO - 11/21/18 18:32:59 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.en.60000.pth ...\n",
            "INFO - 11/21/18 18:32:59 - 0:00:00 - 73804 words (59451 unique) in 3000 sentences.\n",
            "INFO - 11/21/18 18:32:59 - 0:00:00 - 0 unknown word.\n",
            "INFO - 11/21/18 18:32:59 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.zu.60000.pth ...\n",
            "INFO - 11/21/18 18:33:00 - 0:00:00 - 77509 words (59451 unique) in 3000 sentences.\n",
            "INFO - 11/21/18 18:33:00 - 0:00:00 - 0 unknown word.\n",
            "\n",
            "===== Data summary\n",
            "Monolingual training data:\n",
            "    en: /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000.pth\n",
            "    zu: /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000.pth\n",
            "Parallel validation data:\n",
            "    en: /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.en.60000.pth\n",
            "    zu: /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.zu.60000.pth\n",
            "Parallel test data:\n",
            "    en: /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.en.60000.pth\n",
            "    zu: /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.zu.60000.pth\n",
            "\n",
            "Concatenating source and target monolingual data...\n",
            "Concatenated data in: /content/UnsupervisedMT/NMT/data/mono/all.en-zu.60000\n",
            "Training fastText on /content/UnsupervisedMT/NMT/data/mono/all.en-zu.60000...\n",
            "Read 4M words\n",
            "Number of words:  59438\n",
            "Number of labels: 0\n",
            "tcmalloc: large alloc 4217733120 bytes == 0x564a37cce000 @  0x7fd880e36887 0x564a2dd89f73 0x564a2dda37b0 0x564a2dda9f7c 0x564a2dd740f7 0x7fd87fed3b97 0x564a2dd743ba\n",
            "Progress:  15.7% words/sec/thread:     481 lr:  0.042156 loss:  2.360554 ETA:   0h29m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9fpiBbXnfHaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "314b390e-10e6-42e9-9fb7-0769113df340"
      },
      "cell_type": "code",
      "source": [
        "!ls data/mono\n",
        "!ls data/para"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe_codes    mono.en.tok.60000\tmono.zu.tok.60000\t  vocab.en-zu.60000\n",
            "mono.en      mono.zu\t\tnews.2007.en.shuffled.gz  vocab.zu.60000\n",
            "mono.en.tok  mono.zu.tok\tvocab.en.60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wduPhr7hbFny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "## With\n",
        "#usage: run_unsupervised_nmt.sh \n",
        "!TARGET=zu\n",
        "!DUMP_PATH=\n",
        "!MONO_DATASET=\"en:./data/mono/mono.en.tok.60000.pth,,;$TARGET:./data/mono/mono.$TARGET.tok.60000.pth,,\"\n",
        "!PARA_DATASET=\"en-$TARGET:,./data/para/en$TARGET_parallel.dev.en.60000.pth,./data/para/en$TARGET_parallel.dev.$TARGET.60000.pth\"\n",
        "!PRETRAINED=\"./data/mono/all.en-$TARGET.60000.vec\"\n",
        "\n",
        "!echo \"\"\n",
        "!echo \"===== Input parameters =====\"\n",
        "!echo \" TARGET       : $TARGET\"\n",
        "!echo \" MONO_DATASET : $MONO_DATASET\"\n",
        "!echo \" PARA_DATASET : $PARA_DATASET\"\n",
        "!echo \" PRETRAINED   : $PRETRAINED\"\n",
        "!echo \" \"\n",
        "!cd UnsupervisedMT/NMT; python main.py --exp_name en$TARGET \\\n",
        "!    --transformer True  --n_enc_layers 4 --n_dec_layers 4  \\\n",
        "!    --share_enc 3  --share_dec 3  --share_lang_emb True  --share_output_emb True \\\n",
        "!    --langs \"en,$TARGET\" --n_mono -1  --mono_dataset $MONO_DATASET  --para_dataset $PARA_DATASET \\\n",
        "!    --mono_directions \"en,$TARGET\"  --word_shuffle 3 --word_dropout 0.1 --word_blank 0.2 \\\n",
        "!    --pivo_directions \"en-$TARGET-en,$TARGET-en-$TARGET\" \\\n",
        "!    --pretrained_emb $PRETRAINED  --pretrained_out True \\\n",
        "!    --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd 1 \\\n",
        "!    --otf_num_processes 30   --otf_sync_params_every 1000 \\\n",
        "!    --enc_optimizer adam,lr=0.0001 \\\n",
        "!    --group_by_size True \\\n",
        "!    --batch_size 32 \\\n",
        "!    --epoch_size 500000 --stopping_criterion bleu_en_${TARGET}_valid,10 \\\n",
        "!    --freeze_enc_emb False --freeze_dec_emb False \\\n",
        "!    --dump_path $DUMP_PATH        \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attempt on TPU.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ikNFFGD2a1Ky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c19a36a9-b79c-4d33-f674-9a631e24b6ef"
      },
      "cell_type": "code",
      "source": [
        "# Mount Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oYhy9Vx3MQCS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "dffd6358-b1c6-4cb5-dbb7-0508789fca46"
      },
      "cell_type": "code",
      "source": [
        "# Install pytorch using wheel\n",
        "!pip3 install torch torchvision"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 26kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x58eec000 @  0x7fc1590712a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 20.8MB/s \n",
            "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-0.4.1 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D9o5IdtMed3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "18b99194-1024-4db5-b66a-306736e3216e"
      },
      "cell_type": "code",
      "source": [
        "# Install the github repo\n",
        "!git clone https://github.com/jaderabbit/UnsupervisedMT.git\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'UnsupervisedMT' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rx7Wnyp4s4Oe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "4c538453-2a5f-4ba3-9e99-36e0da5850e3"
      },
      "cell_type": "code",
      "source": [
        "!cd UnsupervisedMT; git pull origin master"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/14)   \u001b[K\rremote: Counting objects:  14% (2/14)   \u001b[K\rremote: Counting objects:  21% (3/14)   \u001b[K\rremote: Counting objects:  28% (4/14)   \u001b[K\rremote: Counting objects:  35% (5/14)   \u001b[K\rremote: Counting objects:  42% (6/14)   \u001b[K\rremote: Counting objects:  50% (7/14)   \u001b[K\rremote: Counting objects:  57% (8/14)   \u001b[K\rremote: Counting objects:  64% (9/14)   \u001b[K\rremote: Counting objects:  71% (10/14)   \u001b[K\rremote: Counting objects:  78% (11/14)   \u001b[K\rremote: Counting objects:  85% (12/14)   \u001b[K\rremote: Counting objects:  92% (13/14)   \u001b[K\rremote: Counting objects: 100% (14/14)   \u001b[K\rremote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)   \u001b[K\rremote: Compressing objects: 100% (2/2)   \u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 8 (delta 6), reused 8 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects:  12% (1/8)   \rUnpacking objects:  25% (2/8)   \rUnpacking objects:  37% (3/8)   \rUnpacking objects:  50% (4/8)   \rUnpacking objects:  62% (5/8)   \rUnpacking objects:  75% (6/8)   \rUnpacking objects:  87% (7/8)   \rUnpacking objects: 100% (8/8)   \rUnpacking objects: 100% (8/8), done.\n",
            "From https://github.com/jaderabbit/UnsupervisedMT\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   0705b7c..fa7c72d  master     -> origin/master\n",
            "Updating 0705b7c..fa7c72d\n",
            "Fast-forward\n",
            " NMT/src/utils.py | 6 \u001b[32m+++\u001b[m\u001b[31m---\u001b[m\n",
            " 1 file changed, 3 insertions(+), 3 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HOad2OKLewzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5509
        },
        "outputId": "c481ef83-5819-4bb2-8429-f2d81789b130"
      },
      "cell_type": "code",
      "source": [
        "# cd into github repo\n",
        "# Run preparation\n",
        "!cd UnsupervisedMT/NMT; ./get_my_data.sh zu https://github.com/LauraMartinus/ukuxhumana/raw/master/leipzig/web_2013_100K_mono.zu"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===== Input parameters\n",
            " source: en\n",
            " target: zu\n",
            " target monolingual url: https://github.com/LauraMartinus/ukuxhumana/raw/master/leipzig/web_2013_100K_mono.zu\n",
            " \n",
            "Cloning Moses from GitHub repository...\n",
            "Cloning into 'mosesdecoder'...\n",
            "remote: Enumerating objects: 147198, done.\u001b[K\n",
            "remote: Total 147198 (delta 0), reused 0 (delta 0), pack-reused 147198\u001b[K\n",
            "Receiving objects: 100% (147198/147198), 129.67 MiB | 20.61 MiB/s, done.\n",
            "Resolving deltas: 100% (113765/113765), done.\n",
            "Moses found in: /content/UnsupervisedMT/NMT/tools/mosesdecoder\n",
            "Cloning fastBPE from GitHub repository...\n",
            "Cloning into 'fastBPE'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Total 24 (delta 0), reused 0 (delta 0), pack-reused 24\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n",
            "fastBPE found in: /content/UnsupervisedMT/NMT/tools/fastBPE\n",
            "Compiling fastBPE...\n",
            "fastBPE compiled in: /content/UnsupervisedMT/NMT/tools/fastBPE/fast\n",
            "Cloning fastText from GitHub repository...\n",
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 2729 (delta 42), reused 52 (delta 23), pack-reused 2638\u001b[K\n",
            "Receiving objects: 100% (2729/2729), 7.72 MiB | 20.17 MiB/s, done.\n",
            "Resolving deltas: 100% (1687/1687), done.\n",
            "fastText found in: /content/UnsupervisedMT/NMT/tools/fastText\n",
            "Compiling fastText...\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/args.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/dictionary.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/productquantizer.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/matrix.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/qmatrix.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/vector.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/model.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/utils.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/meter.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -c src/fasttext.cc\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::printLabelStats(std::istream&, int32_t, fasttext::real) const\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:445:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid fasttext::FastText::writePerLabelMetrics(std::ostream&, fasttext::Meter&) const\u001b[m\u001b[K’ is deprecated: This function is deprecated and will be removed along with `printLabelStats`. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   writePerLabelMetrics(std::cout, meter\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ksrc/fasttext.cc:10:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.h:126:8:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   void \u001b[01;36m\u001b[KwritePerLabelMetrics\u001b[m\u001b[K(std::ostream&, Meter&) const;\n",
            "        \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops args.o dictionary.o productquantizer.o matrix.o qmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n",
            "\u001b[01m\u001b[Ksrc/main.cc:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid test(const std::vector<std::__cxx11::basic_string<char> >&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/main.cc:159:51:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid fasttext::FastText::writePerLabelMetrics(std::ostream&, fasttext::Meter&) const\u001b[m\u001b[K’ is deprecated: This function is deprecated and will be removed along with `printLabelStats`. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     fasttext.writePerLabelMetrics(std::cout, meter\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ksrc/main.cc:15:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.h:126:8:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   void \u001b[01;36m\u001b[KwritePerLabelMetrics\u001b[m\u001b[K(std::ostream&, Meter&) const;\n",
            "        \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "fastText compiled in: /content/UnsupervisedMT/NMT/tools/fastText/fasttext\n",
            "Downloading English files...\n",
            "--2018-11-21 18:29:13--  http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2007.en.shuffled.gz\n",
            "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
            "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206963851 (197M) [application/x-gzip]\n",
            "Saving to: ‘news.2007.en.shuffled.gz’\n",
            "\n",
            "news.2007.en.shuffl 100%[===================>] 197.38M  1.55MB/s    in 2m 20s  \n",
            "\n",
            "2018-11-21 18:31:33 (1.41 MB/s) - ‘news.2007.en.shuffled.gz’ saved [206963851/206963851]\n",
            "\n",
            "Downloading zu files...\n",
            "--2018-11-21 18:31:33--  https://github.com/LauraMartinus/ukuxhumana/raw/master/leipzig/web_2013_100K_mono.zu\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/leipzig/web_2013_100K_mono.zu [following]\n",
            "--2018-11-21 18:31:33--  https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/leipzig/web_2013_100K_mono.zu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11324613 (11M) [text/plain]\n",
            "Saving to: ‘mono.zu’\n",
            "\n",
            "mono.zu             100%[===================>]  10.80M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-11-21 18:31:33 (77.9 MB/s) - ‘mono.zu’ saved [11324613/11324613]\n",
            "\n",
            "Decompressing news.2007.en.shuffled.gz...\n",
            "ERROR: Number of lines doesn't match! Be sure you have 100000 sentences in your EN monolingual data.\n",
            "Truncating file...\n",
            "Tokenize monolingual data...\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 48\n",
            "Tokenizer Version 1.1\n",
            "Language: zu\n",
            "Number of threads: 48\n",
            "WARNING: No known abbreviations for language 'zu', attempting fall-back to English version...\n",
            "EN monolingual data tokenized in: /content/UnsupervisedMT/NMT/data/mono/mono.en.tok\n",
            "zu monolingual data tokenized in: /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok\n",
            "Learning BPE codes...\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.en.tok ...\n",
            "Read 2363848 words (100949 unique) from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok ...\n",
            "Read 1557623 words (349064 unique) from text file.\n",
            "tcmalloc: large alloc 12000002048 bytes == 0x56023b990000 @  0x7ff898163887 0x56023089f6fd 0x5602308947ef 0x7ff89759eb97 0x560230894a1a\n",
            "BPE learned in /content/UnsupervisedMT/NMT/data/mono/bpe_codes\n",
            "Applying BPE codes...\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.en.tok ...\n",
            "Read 2363848 words (100949 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/mono/mono.en.tok ...\n",
            "Modified 2363848 words from text file.\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok ...\n",
            "Read 1557623 words (254822 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok ...\n",
            "Modified 1557623 words from text file.\n",
            "BPE codes applied to EN in: /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000\n",
            "BPE codes applied to zu in: /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000\n",
            "Extracting vocabulary...\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000 ...\n",
            "Read 2592092 words (30336 unique) from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000 ...\n",
            "Read 2057480 words (42782 unique) from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000 ...\n",
            "Read 2592092 words (30336 unique) from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000 ...\n",
            "Read 2057480 words (59437 unique) from text file.\n",
            "EN vocab in: /content/UnsupervisedMT/NMT/data/mono/vocab.en.60000\n",
            "zu vocab in: /content/UnsupervisedMT/NMT/data/mono/vocab.zu.60000\n",
            "Full vocab in: /content/UnsupervisedMT/NMT/data/mono/vocab.en-zu.60000\n",
            "Binarizing data...\n",
            "INFO - 11/21/18 18:32:45 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000.pth ...\n",
            "INFO - 11/21/18 18:32:48 - 0:00:03 - 2592092 words (59451 unique) in 100000 sentences.\n",
            "INFO - 11/21/18 18:32:48 - 0:00:03 - 0 unknown word.\n",
            "INFO - 11/21/18 18:32:49 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000.pth ...\n",
            "INFO - 11/21/18 18:32:52 - 0:00:03 - 2057480 words (59451 unique) in 100000 sentences.\n",
            "INFO - 11/21/18 18:32:52 - 0:00:03 - 0 unknown word.\n",
            "EN binarized data in: /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000.pth\n",
            "zu binarized data in: /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000.pth\n",
            "Downloading parallel data...\n",
            "--2018-11-21 18:32:52--  https://github.com/LauraMartinus/ukuxhumana/raw/master/clean/en_zu/enzu_parallel.dev.en\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.dev.en [following]\n",
            "--2018-11-21 18:32:52--  https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.dev.en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 586751 (573K) [text/plain]\n",
            "Saving to: ‘enzu_parallel.dev.en’\n",
            "\n",
            "enzu_parallel.dev.e 100%[===================>] 573.00K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2018-11-21 18:32:52 (5.94 MB/s) - ‘enzu_parallel.dev.en’ saved [586751/586751]\n",
            "\n",
            "--2018-11-21 18:32:52--  https://github.com/LauraMartinus/ukuxhumana/raw/master/clean/en_zu/enzu_parallel.dev.zu\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.dev.zu [following]\n",
            "--2018-11-21 18:32:52--  https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.dev.zu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 623825 (609K) [text/plain]\n",
            "Saving to: ‘enzu_parallel.dev.zu’\n",
            "\n",
            "enzu_parallel.dev.z 100%[===================>] 609.20K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2018-11-21 18:32:52 (9.63 MB/s) - ‘enzu_parallel.dev.zu’ saved [623825/623825]\n",
            "\n",
            "--2018-11-21 18:32:52--  https://github.com/LauraMartinus/ukuxhumana/raw/master/clean/en_zu/enzu_parallel.test.en\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.test.en [following]\n",
            "--2018-11-21 18:32:53--  https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.test.en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 377479 (369K) [text/plain]\n",
            "Saving to: ‘enzu_parallel.test.en’\n",
            "\n",
            "enzu_parallel.test. 100%[===================>] 368.63K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2018-11-21 18:32:53 (7.21 MB/s) - ‘enzu_parallel.test.en’ saved [377479/377479]\n",
            "\n",
            "--2018-11-21 18:32:53--  https://github.com/LauraMartinus/ukuxhumana/raw/master/clean/en_zu/enzu_parallel.test.zu\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.test.zu [following]\n",
            "--2018-11-21 18:32:53--  https://raw.githubusercontent.com/LauraMartinus/ukuxhumana/master/clean/en_zu/enzu_parallel.test.zu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 403406 (394K) [text/plain]\n",
            "Saving to: ‘enzu_parallel.test.zu’\n",
            "\n",
            "enzu_parallel.test. 100%[===================>] 393.95K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2018-11-21 18:32:53 (7.66 MB/s) - ‘enzu_parallel.test.zu’ saved [403406/403406]\n",
            "\n",
            "Extracting parallel data...\n",
            "Tokenizing valid and test data...\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 48\n",
            "Tokenizer Version 1.1\n",
            "Language: zu\n",
            "Number of threads: 48\n",
            "WARNING: No known abbreviations for language 'zu', attempting fall-back to English version...\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 48\n",
            "Tokenizer Version 1.1\n",
            "Language: zu\n",
            "Number of threads: 48\n",
            "WARNING: No known abbreviations for language 'zu', attempting fall-back to English version...\n",
            "Applying BPE to valid and test files...\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/vocab.en.60000 ...\n",
            "Read 2592092 words (30336 unique) from vocabulary file.\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.en ...\n",
            "Read 104371 words (8205 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.en ...\n",
            "Modified 104371 words from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/vocab.zu.60000 ...\n",
            "Read 2057480 words (42782 unique) from vocabulary file.\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.zu ...\n",
            "Read 73915 words (20623 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.zu ...\n",
            "Modified 73915 words from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/vocab.en.60000 ...\n",
            "Read 2592092 words (30336 unique) from vocabulary file.\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.en ...\n",
            "Read 65604 words (6694 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.en ...\n",
            "Modified 65604 words from text file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/mono/vocab.zu.60000 ...\n",
            "Read 2057480 words (42782 unique) from vocabulary file.\n",
            "Loading codes from /content/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.zu ...\n",
            "Read 48512 words (14309 unique) from text file.\n",
            "Applying BPE to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.zu ...\n",
            "Modified 48512 words from text file.\n",
            "Binarizing data...\n",
            "INFO - 11/21/18 18:32:57 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.en.60000.pth ...\n",
            "INFO - 11/21/18 18:32:57 - 0:00:00 - 113806 words (59451 unique) in 5019 sentences.\n",
            "INFO - 11/21/18 18:32:57 - 0:00:00 - 0 unknown word.\n",
            "INFO - 11/21/18 18:32:58 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.zu.60000.pth ...\n",
            "INFO - 11/21/18 18:32:58 - 0:00:00 - 113824 words (59451 unique) in 5019 sentences.\n",
            "INFO - 11/21/18 18:32:58 - 0:00:00 - 0 unknown word.\n",
            "INFO - 11/21/18 18:32:59 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.en.60000.pth ...\n",
            "INFO - 11/21/18 18:32:59 - 0:00:00 - 73804 words (59451 unique) in 3000 sentences.\n",
            "INFO - 11/21/18 18:32:59 - 0:00:00 - 0 unknown word.\n",
            "INFO - 11/21/18 18:32:59 - 0:00:00 - Read 59451 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.zu.60000.pth ...\n",
            "INFO - 11/21/18 18:33:00 - 0:00:00 - 77509 words (59451 unique) in 3000 sentences.\n",
            "INFO - 11/21/18 18:33:00 - 0:00:00 - 0 unknown word.\n",
            "\n",
            "===== Data summary\n",
            "Monolingual training data:\n",
            "    en: /content/UnsupervisedMT/NMT/data/mono/mono.en.tok.60000.pth\n",
            "    zu: /content/UnsupervisedMT/NMT/data/mono/mono.zu.tok.60000.pth\n",
            "Parallel validation data:\n",
            "    en: /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.en.60000.pth\n",
            "    zu: /content/UnsupervisedMT/NMT/data/para/enzu_parallel.dev.zu.60000.pth\n",
            "Parallel test data:\n",
            "    en: /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.en.60000.pth\n",
            "    zu: /content/UnsupervisedMT/NMT/data/para/enzu_parallel.test.zu.60000.pth\n",
            "\n",
            "Concatenating source and target monolingual data...\n",
            "Concatenated data in: /content/UnsupervisedMT/NMT/data/mono/all.en-zu.60000\n",
            "Training fastText on /content/UnsupervisedMT/NMT/data/mono/all.en-zu.60000...\n",
            "Read 4M words\n",
            "Number of words:  59438\n",
            "Number of labels: 0\n",
            "tcmalloc: large alloc 4217733120 bytes == 0x564a37cce000 @  0x7fd880e36887 0x564a2dd89f73 0x564a2dda37b0 0x564a2dda9f7c 0x564a2dd740f7 0x7fd87fed3b97 0x564a2dd743ba\n",
            "Progress: 100.0% words/sec/thread:     528 lr:  0.000000 loss:  2.073761 ETA:   0h 0m\n",
            "Cross-lingual embeddings in: /content/UnsupervisedMT/NMT/data/mono/all.en-zu.60000.vec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9fpiBbXnfHaI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save weights to drive\n",
        "file_path='/content/UnsupervisedMT/NMT/data/mono/all.en-zu.60000.vec'\n",
        "destination_path='/content/gdrive/My Drive/NMT/all.en-zu.60000.vec'\n",
        "with open(destination_path, 'w') as f:\n",
        "  with open(file_path,'r') as to_move:\n",
        "    f.write(to_move.read())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wduPhr7hbFny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "f908645a-3aa1-485b-e015-b8bbbb9bf0b4"
      },
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "## With\n",
        "#usage: run_unsupervised_nmt.sh \n",
        "!cd UnsupervisedMT/NMT; ./run_unsupervised_nmt.sh zu \"/content/gdrive/My Drive/NMT/\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===== Input parameters =====\n",
            " TARGET       : zu\n",
            " MONO_DATASET : en:./data/mono/mono.en.tok.60000.pth,,;zu:./data/mono/mono.zu.tok.60000.pth,,\n",
            " PARA_DATASET : en-zu:,./data/para/en.dev.en.60000.pth,./data/para/en.dev.zu.60000.pth\n",
            " PRETRAINED   : ./data/mono/all.en-zu.60000.vec\n",
            " \n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 236, in <module>\n",
            "    check_all_data_params(params)\n",
            "  File \"/content/UnsupervisedMT/NMT/src/data/loader.py\", line 341, in check_all_data_params\n",
            "    assert os.path.isfile(valid_path.replace('XX', lang1))\n",
            "AssertionError\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mu_tE7NusVjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3061
        },
        "outputId": "236492a2-bc3a-4605-b010-afaea50f12d9"
      },
      "cell_type": "code",
      "source": [
        "!cd UnsupervisedMT/NMT; python -u main.py --exp_name enzu     --transformer True  --n_enc_layers 4 --n_dec_layers 4      --share_enc 3  --share_dec 3  --share_lang_emb True  --share_output_emb True     --langs \"en,zu\" --n_mono -1  --mono_dataset \"en:./data/mono/mono.en.tok.60000.pth,,;zu:./data/mono/mono.zu.tok.60000.pth,,\"  --para_dataset \"en-zu:,./data/para/enzu_parallel.dev.en.60000.pth,./data/para/enzu_parallel.dev.zu.60000.pth\"     --mono_directions \"en,zu\"  --word_shuffle 3 --word_dropout 0.1 --word_blank 0.2     --pivo_directions \"en-zu-en,zu-en-zu\"     --pretrained_emb \"./data/mono/all.en-zu.60000.vec\"  --pretrained_out True     --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd 1     --otf_num_processes 30   --otf_sync_params_every 1000     --enc_optimizer adam,lr=0.0001     --group_by_size True     --batch_size 32     --epoch_size 500000 --stopping_criterion bleu_en_zu_valid,10     --freeze_enc_emb False --freeze_dec_emb False     --dump_path \"/content/gdrive/My Drive/NMT\"        \n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 11/21/18 19:39:02 - 0:00:00 - ============ Initialized logger ============\n",
            "INFO - 11/21/18 19:39:02 - 0:00:00 - attention: True\n",
            "                                     attention_dropout: 0\n",
            "                                     back_dataset: {}\n",
            "                                     back_directions: []\n",
            "                                     batch_size: 32\n",
            "                                     beam_size: 0\n",
            "                                     clip_grad_norm: 5\n",
            "                                     command: python main.py --exp_name 'enzu' --transformer 'True' --n_enc_layers '4' --n_dec_layers '4' --share_enc '3' --share_dec '3' --share_lang_emb 'True' --share_output_emb 'True' --langs 'en,zu' --n_mono '-1' --mono_dataset 'en:./data/mono/mono.en.tok.60000.pth,,;zu:./data/mono/mono.zu.tok.60000.pth,,' --para_dataset 'en-zu:,./data/para/enzu_parallel.dev.en.60000.pth,./data/para/enzu_parallel.dev.zu.60000.pth' --mono_directions 'en,zu' --word_shuffle '3' --word_dropout '0.1' --word_blank '0.2' --pivo_directions 'en-zu-en,zu-en-zu' --pretrained_emb './data/mono/all.en-zu.60000.vec' --pretrained_out 'True' --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd '1' --otf_num_processes '30' --otf_sync_params_every '1000' --enc_optimizer 'adam,lr=0.0001' --group_by_size 'True' --batch_size '32' --epoch_size '500000' --stopping_criterion 'bleu_en_zu_valid,10' --freeze_enc_emb 'False' --freeze_dec_emb 'False' --dump_path '/content/gdrive/My Drive/NMT' --exp_id \"inm53goylo\"\n",
            "                                     dec_optimizer: enc_optimizer\n",
            "                                     decoder_attention_heads: 8\n",
            "                                     decoder_normalize_before: False\n",
            "                                     dis_clip: 0\n",
            "                                     dis_dropout: 0\n",
            "                                     dis_hidden_dim: 128\n",
            "                                     dis_input_proj: True\n",
            "                                     dis_layers: 3\n",
            "                                     dis_optimizer: rmsprop,lr=0.0005\n",
            "                                     dis_smooth: 0\n",
            "                                     dropout: 0\n",
            "                                     dump_path: /content/gdrive/My Drive/NMT/enzu/inm53goylo\n",
            "                                     emb_dim: 512\n",
            "                                     enc_optimizer: adam,lr=0.0001\n",
            "                                     encoder_attention_heads: 8\n",
            "                                     encoder_normalize_before: False\n",
            "                                     epoch_size: 500000\n",
            "                                     eval_only: False\n",
            "                                     exp_id: inm53goylo\n",
            "                                     exp_name: enzu\n",
            "                                     freeze_dec_emb: False\n",
            "                                     freeze_enc_emb: False\n",
            "                                     group_by_size: True\n",
            "                                     hidden_dim: 512\n",
            "                                     id2lang: {0: 'en', 1: 'zu'}\n",
            "                                     label_smoothing: 0\n",
            "                                     lambda_dis: 0\n",
            "                                     lambda_lm: 0\n",
            "                                     lambda_xe_back: 0\n",
            "                                     lambda_xe_mono: 0:1,100000:0.1,300000:0\n",
            "                                     lambda_xe_otfa: 0\n",
            "                                     lambda_xe_otfd: 1\n",
            "                                     lambda_xe_para: 0\n",
            "                                     lang2id: {'en': 0, 'zu': 1}\n",
            "                                     langs: ['en', 'zu']\n",
            "                                     length_penalty: 1.0\n",
            "                                     lm_after: 0\n",
            "                                     lm_before: 0\n",
            "                                     lm_share_dec: 0\n",
            "                                     lm_share_emb: False\n",
            "                                     lm_share_enc: 0\n",
            "                                     lm_share_proj: False\n",
            "                                     lstm_proj: False\n",
            "                                     max_epoch: 100000\n",
            "                                     max_len: 175\n",
            "                                     max_vocab: -1\n",
            "                                     mono_dataset: {'en': ('./data/mono/mono.en.tok.60000.pth', '', ''), 'zu': ('./data/mono/mono.zu.tok.60000.pth', '', '')}\n",
            "                                     mono_directions: ['en', 'zu']\n",
            "                                     n_back: 0\n",
            "                                     n_dec_layers: 4\n",
            "                                     n_dis: 0\n",
            "                                     n_enc_layers: 4\n",
            "                                     n_langs: 2\n",
            "                                     n_mono: -1\n",
            "                                     n_para: 0\n",
            "                                     otf_backprop_temperature: -1\n",
            "                                     otf_num_processes: 30\n",
            "                                     otf_sample: -1\n",
            "                                     otf_sync_params_every: 1000\n",
            "                                     otf_update_dec: True\n",
            "                                     otf_update_enc: True\n",
            "                                     para_dataset: {('en', 'zu'): ('', './data/para/enzu_parallel.dev.en.60000.pth', './data/para/enzu_parallel.dev.zu.60000.pth')}\n",
            "                                     para_directions: []\n",
            "                                     pivo_directions: [('en', 'zu', 'en'), ('zu', 'en', 'zu')]\n",
            "                                     pretrained_emb: ./data/mono/all.en-zu.60000.vec\n",
            "                                     pretrained_out: True\n",
            "                                     reload_dec: False\n",
            "                                     reload_dis: False\n",
            "                                     reload_enc: False\n",
            "                                     reload_model: \n",
            "                                     relu_dropout: 0\n",
            "                                     save_periodic: False\n",
            "                                     seed: -1\n",
            "                                     share_dec: 3\n",
            "                                     share_decpro_emb: False\n",
            "                                     share_enc: 3\n",
            "                                     share_encdec_emb: False\n",
            "                                     share_lang_emb: True\n",
            "                                     share_lstm_proj: False\n",
            "                                     share_output_emb: True\n",
            "                                     stopping_criterion: bleu_en_zu_valid,10\n",
            "                                     transformer: True\n",
            "                                     transformer_ffn_emb_dim: 2048\n",
            "                                     vocab: {}\n",
            "                                     vocab_min_count: 0\n",
            "                                     word_blank: 0.2\n",
            "                                     word_dropout: 0.1\n",
            "                                     word_shuffle: 3.0\n",
            "INFO - 11/21/18 19:39:02 - 0:00:00 - The experiment will be stored in /content/gdrive/My Drive/NMT/enzu/inm53goylo\n",
            "                                     \n",
            "INFO - 11/21/18 19:39:02 - 0:00:00 - Running command: python main.py --exp_name 'enzu' --transformer 'True' --n_enc_layers '4' --n_dec_layers '4' --share_enc '3' --share_dec '3' --share_lang_emb 'True' --share_output_emb 'True' --langs 'en,zu' --n_mono '-1' --mono_dataset 'en:./data/mono/mono.en.tok.60000.pth,,;zu:./data/mono/mono.zu.tok.60000.pth,,' --para_dataset 'en-zu:,./data/para/enzu_parallel.dev.en.60000.pth,./data/para/enzu_parallel.dev.zu.60000.pth' --mono_directions 'en,zu' --word_shuffle '3' --word_dropout '0.1' --word_blank '0.2' --pivo_directions 'en-zu-en,zu-en-zu' --pretrained_emb './data/mono/all.en-zu.60000.vec' --pretrained_out 'True' --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd '1' --otf_num_processes '30' --otf_sync_params_every '1000' --enc_optimizer 'adam,lr=0.0001' --group_by_size 'True' --batch_size '32' --epoch_size '500000' --stopping_criterion 'bleu_en_zu_valid,10' --freeze_enc_emb 'False' --freeze_dec_emb 'False' --dump_path '/content/gdrive/My Drive/NMT' --exp_id \"inm53goylo\"\n",
            "                                     \n",
            "INFO - 11/21/18 19:39:02 - 0:00:00 - ============ Parallel data (en - zu)\n",
            "INFO - 11/21/18 19:39:02 - 0:00:00 - Loading data from ./data/para/enzu_parallel.dev.en.60000.pth ...\n",
            "INFO - 11/21/18 19:39:02 - 0:00:00 - 113806 words (59451 unique) in 5019 sentences. 0 unknown words (0 unique).\n",
            "INFO - 11/21/18 19:39:02 - 0:00:00 - Reloading data loaded from ./data/para/enzu_parallel.dev.en.60000.pth ...\n",
            "INFO - 11/21/18 19:39:02 - 0:00:00 - Removed 0 empty sentences.\n",
            "INFO - 11/21/18 19:39:02 - 0:00:00 - Removed 0 too long sentences.\n",
            "INFO - 11/21/18 19:39:02 - 0:00:00 - Loading data from ./data/para/enzu_parallel.dev.zu.60000.pth ...\n",
            "INFO - 11/21/18 19:39:03 - 0:00:00 - 113824 words (59451 unique) in 5019 sentences. 0 unknown words (0 unique).\n",
            "INFO - 11/21/18 19:39:03 - 0:00:00 - Reloading data loaded from ./data/para/enzu_parallel.dev.zu.60000.pth ...\n",
            "INFO - 11/21/18 19:39:03 - 0:00:00 - Removed 0 empty sentences.\n",
            "\n",
            "\n",
            "INFO - 11/21/18 19:39:03 - 0:00:01 - ============ Monolingual data (en)\n",
            "INFO - 11/21/18 19:39:03 - 0:00:01 - Loading data from ./data/mono/mono.en.tok.60000.pth ...\n",
            "INFO - 11/21/18 19:39:04 - 0:00:02 - 2592092 words (59451 unique) in 100000 sentences. 0 unknown words (0 unique).\n",
            "INFO - 11/21/18 19:39:04 - 0:00:02 - Removed 0 empty sentences.\n",
            "INFO - 11/21/18 19:39:04 - 0:00:02 - Removed 85 too long sentences.\n",
            "INFO - 11/21/18 19:39:04 - 0:00:02 - ============ Monolingual data (zu)\n",
            "INFO - 11/21/18 19:39:04 - 0:00:02 - Loading data from ./data/mono/mono.zu.tok.60000.pth ...\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - 2057480 words (59451 unique) in 100000 sentences. 0 unknown words (0 unique).\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Removed 0 empty sentences.\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Removed 0 too long sentences.\n",
            "\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - ============ Data summary\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Parallel data      - valid -   en ->   zu:      5019\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Parallel data      -  test -   en ->   zu:      5019\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Monolingual data   - train -           en:     99915\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Monolingual data   - valid -           en:         0\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Monolingual data   -  test -           en:         0\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Monolingual data   - train -           zu:    100000\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Monolingual data   - valid -           zu:         0\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Monolingual data   -  test -           zu:         0\n",
            "\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - ============ Building transformer attention model - Encoder ...\n",
            "INFO - 11/21/18 19:39:05 - 0:00:03 - Sharing encoder input embeddings\n",
            "INFO - 11/21/18 19:39:06 - 0:00:04 - Sharing encoder transformer parameters for layer 1\n",
            "INFO - 11/21/18 19:39:06 - 0:00:04 - Sharing encoder transformer parameters for layer 2\n",
            "INFO - 11/21/18 19:39:06 - 0:00:04 - Sharing encoder transformer parameters for layer 3\n",
            "\n",
            "INFO - 11/21/18 19:39:06 - 0:00:04 - ============ Building transformer attention model - Decoder ...\n",
            "INFO - 11/21/18 19:39:06 - 0:00:04 - Sharing decoder input embeddings\n",
            "INFO - 11/21/18 19:39:07 - 0:00:05 - Sharing decoder transformer parameters for layer 0\n",
            "INFO - 11/21/18 19:39:07 - 0:00:05 - Sharing decoder transformer parameters for layer 1\n",
            "INFO - 11/21/18 19:39:07 - 0:00:05 - Sharing decoder transformer parameters for layer 2\n",
            "INFO - 11/21/18 19:39:08 - 0:00:06 - Sharing decoder projection matrices\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=30 : unknown error\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 242, in <module>\n",
            "    encoder, decoder, discriminator, lm = build_mt_model(params, data)\n",
            "  File \"/content/UnsupervisedMT/NMT/src/model/__init__.py\", line 98, in build_mt_model\n",
            "    return build_attention_model(params, data, cuda=cuda)\n",
            "  File \"/content/UnsupervisedMT/NMT/src/model/attention.py\", line 801, in build_attention_model\n",
            "    encoder.cuda()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 258, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 185, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 185, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 191, in _apply\n",
            "    param.data = fn(param.data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 258, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "RuntimeError: cuda runtime error (30) : unknown error at /pytorch/aten/src/THC/THCGeneral.cpp:74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c2qKGpgavNd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.path.isdir(\"/content/gdrive/My Drive/\")\n",
        "!mkdir /content/gdrive/My\\ Drive/test"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}